@article{eliza,
author = {Weizenbaum, Joseph},
title = {ELIZA—a Computer Program for the Study of Natural Language Communication between Man and Machine},
year = {1966},
issue_date = {Jan. 1966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/365153.365168},
doi = {10.1145/365153.365168},
journal = {Commun. ACM},
month = {jan},
pages = {36–45},
numpages = {10}
}
@article{Raffel2019ExploringTL,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Colin Raffel and Noam M. Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.10683}
}
@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and T. J. Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}
@article{Vaswani2017AttentionIA,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.03762}
}
@article{Bahdanau2015EndtoendAL,
  title={End-to-end attention-based large vocabulary speech recognition},
  author={Dzmitry Bahdanau and Jan Chorowski and Dmitriy Serdyuk and Philemon Brakel and Yoshua Bengio},
  journal={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2015},
  pages={4945-4949}
}
@article{Graves2013GeneratingSW,
  title={Generating Sequences With Recurrent Neural Networks},
  author={Alex Graves},
  journal={ArXiv},
  year={2013},
  volume={abs/1308.0850}
} 
@inproceedings{Perez2022RedTL,
  title={Red Teaming Language Models with Language Models},
  author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nathan McAleese and Geoffrey Irving},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022}
}
@article{OpenAI2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774}
}
@inproceedings{Groenwold2020DatsWI,
  title={Dats Wassup!!: Investigating African-American Vernacular English in Transformer-Based Text Generation},
  author={Sophie Groenwold and Li-hsueh Ou and Aesha Parekh and Samhita Honnavalli and Sharon Levy and Diba Mirza and William Yang Wang},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2020}
}
@inproceedings{Zhang2021SociolectalAO,
  title={Sociolectal Analysis of Pretrained Language Models},
  author={Sheng Zhang and Xin Zhang and Weiming Zhang and Anders S{\o}gaard},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2021}
}
@inproceedings{Smith2022ImST,
  title={“I’m sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Dataset},
  author={Eric J. M. Smith and Melissa Hall and Melanie Kambadur and Eleonora Presani and Adina Williams},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022}
}
@inproceedings{Huang2022AreLP,
  title={Are Large Pre-Trained Language Models Leaking Your Personal Information?},
  author={Jie Huang and Hanyin Shao and Kevin Chen-Chuan Chang},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022}
}
@article{Ganguli2022RedTL,
  title={Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned},
  author={Deep Ganguli and Liane Lovitt and John Kernion and Amanda Askell and Yuntao Bai and Saurav Kadavath and Benjamin Mann and Ethan Perez and Nicholas Schiefer and Kamal Ndousse and Andy Jones and Sam Bowman and Anna Chen and Tom Conerly and Nova DasSarma and Dawn Drain and Nelson Elhage and Sheer El-Showk and Stanislav Fort and Zachary Dodds and T. J. Henighan and Danny Hernandez and Tristan Hume and Josh Jacobson and Scott Johnston and Shauna Kravec and Catherine Olsson and Sam Ringer and Eli Tran-Johnson and Dario Amodei and Tom B. Brown and Nicholas Joseph and Sam McCandlish and Christopher Olah and Jared Kaplan and Jack Clark},
  journal={ArXiv},
  year={2022},
  volume={abs/2209.07858}
}
@inproceedings{Blodgett2020LanguageI,
  title={Language (Technology) is Power: A Critical Survey of “Bias” in NLP},
  author={Su Lin Blodgett and Solon Barocas and Hal Daum'e and Hanna M. Wallach},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2020}
}
@article{Chang2023LanguageMB,
  title={Language Model Behavior: A Comprehensive Survey},
  author={Tyler A. Chang and Benjamin K. Bergen},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.11504}
}
@article{Hallucination,
author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
title = {Survey of Hallucination in Natural Language Generation},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3571730},
doi = {10.1145/3571730},
abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {248},
numpages = {38},
keywords = {factuality in NLG, intrinsic hallucination, Hallucination, faithfulness in NLG, consistency in NLG, extrinsic hallucination}
}
@inproceedings{Mikolov2010RecurrentNN,
  title={Recurrent neural network based language model},
  author={Tomas Mikolov and Martin Karafi{\'a}t and Luk{\'a}{\vs} Burget and Jan Honza {\v{C}}ernock{\'y} and Sanjeev Khudanpur},
  booktitle={Interspeech},
  year={2010}
}

@inproceedings{Winograd1971ProceduresAA,
  title={Procedures As A Representation For Data In A Computer Program For Understanding Natural Language},
  author={Terry Winograd},
  year={1971}
}
@patent{wilkinson_1990,
  author        = {J. P. Wilkinson},
  title         = {Nonlinear resonant circuit devices},
  address   = {United States},
  number        = {3 624 125},
  day           = {16},
  month         = {aug},
  year          = {1990},
}
@techreport{SP80053r4,
   author = {{Joint Task Force Transformation Initiative Interagency Working Group}},
   title = {Security and Privacy Controls for Federal Information Systems and Organizations},
   institution = {National Institute of Standards and Technology},
   address= {Gaithersburg, MD},
   number = {NIST Special Publication (SP) 800-53, Rev. 4, Includes updates as of January 22, 2015},
   DOI = {10.6028/NIST.SP.800-53r4},
   year = {2013},
}
@techreport{FIPS1402,
   author = {{National Institute of Standards and Technology}},
   title = {Security Requirements for Cryptographic Modules},
   institution = {U.S. Department of Commerce},
   address= {Washington, D.C.},
   number = {Federal Information Processing Standards Publications (FIPS PUBS) 140-2, Change Notice 2 December 03, 2002},
   DOI = {10.6028/NIST.FIPS.140-2},
   year = {2001},
}
@ARTICLE{Xiong2015, 
	author={H. Xiong}, 
	journal={Chinese Journal of Electronics}, 
	title={Multi-level Bell-Type Inequality from Information Causality and Noisy Computations}, 
	year={2015}, 
	volume={24}, 
	number={2}, 
	pages={408-413}, 
	keywords={communication complexity;probability;quantum communication;quantum computing;NS-box;RAC;Tsirelson bounds;communication complexity;independent identically distribution;information causality;multilevel Bell-type inequality;no-signaling box;noisy computations;nonlocal quantum computation;random access code;symmetric quantum channels;uniform input marginal probabilities}, 
	doi={10.1049/cje.2015.04.031}, 
	ISSN={1022-4653}, 
	month={},}


@ARTICLE{Prives2016, 
	author={L. Prives}, 
	journal={IEEE Women in Engineering Magazine}, 
	title={For Whom the Bell Tolls: Inventing success through creativity and analytical skills [WIE from Around the World]}, 
	year={2016}, 
	volume={10}, 
	number={1}, 
	pages={37-39}, 
	keywords={Creativity;Education;Engineering profession;Media;Technological innovation}, 
	doi={10.1109/MWIE.2016.2535841}, 
	ISSN={1942-065X}, 
	month={June},}

@ARTICLE{Roberts1982, 
	author={L. J. Roberts}, 
	journal={SMPTE Journal}, 
	title={Cameras and Systems: A History of Contributions from the Bell; Howell Co. (Part I)}, 
	year={1982}, 
	volume={91}, 
	number={10}, 
	pages={934-946}, 
	doi={10.5594/J00229}, 
	ISSN={0036-1682}, 
	month={Oct},}

@INPROCEEDINGS{Maloney2016, 
	author={T. J. Maloney}, 
	booktitle={38th Electrical Overstress/Electrostatic Discharge Symposium (EOS/ESD)}, 
	title={Unified model of 1-D pulsed heating, combining Wunsch-Bell with the Dwyer curve: This paper is co-copyrighted by Intel Corporation and the ESD association}, 
	year={2016}, 
	pages={1-8}, 
	keywords={electrostatic discharge;heat sinks;heat transfer;integrated circuit modelling;1-D pulsed heating;Dwyer curve;Wunsch-Bell relation;heat flow;power-to-fail curves;Analytical models;Convolution;Heat sinks;Impedance;Resistance heating;Steady-state}, 
	doi={10.1109/EOSESD.2016.7592562}, 
	volume=22,
	publisher={Publisher name, location},
	month={Sept},}

@book{giancoli2008physics,
	title={Physics for Scientists and Engineers with Modern Physics},
	author={Giancoli, D.C.},
	isbn={9780131495081},
	lccn={2006039431},
	pages = {123-124},
	edition = {4},
	year={2008},
	publisher={Pearson Education}
}

@inbook{Eston1993,
	author       = {Peter Eston}, 
	title        = {Book section title},
	pages        = {201-213},
	chapter = {8},
	publisher    = {The name of the publisher},
	address    = {The address of the publisher},
	year         = {1993},
	volume       = {4},
	edition      = {3},
	month        = {7},
}

@TECHREPORT{MSU-CSE-06-2,
	AUTHOR =        {R. Behrends and L. K. Dillon and S. D. Fleming and
	R. E. K. Stirewalt},
	TITLE =         {White paper: Programming according to the fences and gates
	model for developing assured, secure software
	systems},
	NUMBER =        {MSU-CSE-06-2},
	INSTITUTION =   {Department of Computer Science, Michigan State University},
	ADDRESS =       {East Lansing, Michigan},
	ABSTRACT =      {This white paper describes extensions to our work on the
	Synchronization Units Model (Szumo) to address the
	access-control problem in systems assembled dynamically from
	trusted and untrusted components. Our extension employs
	explicitly declared design contracts, the semantics of which
	are founded on Landwehr's model of fences and gates.
	},
	KEYWORDS =      {access control, security, contracts, Szumo},
	NOTE =          {},
	MONTH =         {January},
	YEAR  =         {2006},
	AUTHOR1_URL =   {http://www.poker-ping.info},
	AUTHOR1_EMAIL = {kel@wondering-jons.com},
	AUTHOR1_URL =   {},
	AUTHOR1_EMAIL = {behrends@cse.msu.edu},
	AUTHOR2_URL =   {Sle},
	AUTHOR2_EMAIL = {Poker Ping},
	AUTHOR2_URL =   {http://www.cse.msu.edu/~stire},
	AUTHOR2_EMAIL = {stire@cse.msu.edu},
	PAGES =         {3},
	FILE  =         {/user/web/htdocs/publications/tech/TR/MSU-CSE-06-2.ps},
	DOI   =         {},
	CONTACT =       {stire@cse.msu.edu}
}


@incollection{Farindon,
	author       = {Peter Farindon}, 
	title        = {The title of the collection section},
	booktitle    = {The title of the book},
	publisher    = {The name of the publisher},
	year         = {1993},
	editor       = {Firstname Lastname},
	volume       = {4},
	chapter      = {8},
	pages        = {201-213},
	address      = {The address of the publisher},
	edition      = {3},
	month        = {7},
	DOI         = {}
}

@unpublished{Marcheford,
	author       = {Peter Marcheford}, 
	title        = {The title of the unpublished work},
	month        = {7},
	year         = {1993}
}

@phdthesis{Joslin,
	author       = {Peter Joslin}, 
	title        = {The title of the PhD Thesis},
	school       = {The school of the thesis},
	year         = {1993},
	address      = {The address of the publisher},
	month        = {7},
	note         = {An optional note}
}
@booklet{Caxton,
	title        = {The title of the booklet},
	author       = {Peter Caxton}, 
	howpublished = {How it was published},
	address      = {The address of the publisher},
	month        = {7},
	year         = {1993},
	note         = {An optional note}
}


@misc{Isley,
	author       = {Peter Isley}, 
	title        = {The title of the webpage},
	month        = {7},
	year         = {1993},
	url         = {https://nist.gov}
}       

 @article{alkaissi_mcfarlane_2023, 
        title = {Artificial hallucinations in CHATGPT: Implications in scientific writing},
        DOI = {10.7759/cureus.35179},
        journal = {Cureus}, 
        author = {Alkaissi, Hussam and McFarlane, Samy I}, 
        year = {2023}
} 

@misc{mandiberg_2020, 
    title = {Mapping wikipedia}, 
    url = {https://www.theatlantic.com/technology/archive/2020/02/where-wikipedias-editors-are-where-they-arent-and-why/605023/},
    journal = {The Atlantic}, 
    publisher = {Atlantic Media Company}, 
    author = {Mandiberg, Michael}, 
    year = {2020}, 
    month = {Feb}
} 

@misc{eleuther-ai, 
    url={https://pile.eleuther.ai/}, 
    journal={The Pile}, 
    author={Eleuther AI}
} 

@misc{kojima2023large,
      title={Large Language Models are Zero-Shot Reasoners}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shaikh2022second,
      title={On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning}, 
      author={Omar Shaikh and Hongxin Zhang and William Held and Michael Bernstein and Diyi Yang},
      year={2022},
      eprint={2212.08061},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{bushwick_2022, 
    title={ChatGPT explains why AIs like ChatGPT should be regulated},
    url={https://www.scientificamerican.com/article/chatgpt-explains-why-ais-like-chatgpt-should-be-regulated1/}, 
    journal={Scientific American}, 
    publisher={Scientific American}, 
    author={Bushwick, Sophie}, 
    year={2022}, 
    month={Dec}
} 

@misc{introducing_chatgpt_2022, url={https://openai.com/blog/chatgpt}, journal={Introducing ChatGPT}, year={2022}, month={Nov}} 

@misc{luccioni , url={https://docs.google.com/presentation/d/1FRoyzdodKQ7-5rK--gZFFzK_-kvfhzxJQDYxpnA-6jE/edit\#slide=id.g227c15f28ed_0_46}, journal={Generative AI: Sasha Luccioni [Public Version]}, author={Luccioni , Sasha}} 

 @misc{taylor_2023, title={Chatgpt's alter ego, Dan: Users jailbreak AI program to get around ethical safeguards}, url={https://www.theguardian.com/technology/2023/mar/08/chatgpt-alter-ego-dan-users-jailbreak-ai-program-to-get-around-ethical-safeguards}, journal={The Guardian}, publisher={Guardian News and Media}, author={Taylor, Josh}, year={2023}, month={Mar}} 